{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Guilherme Leite\n",
    "\n",
    "## Leonardo Neves\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e\n",
    "    25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Leonardo\\OneDrive\\insper\\dps_2018\\ciencia_dos_dados\\projeto_2\\DPCD-master\\P2\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('spamham.xlsx') #le o arquivo\n",
    "\n",
    "df = df.replace(',','',regex=True)\n",
    "df = df.replace('@','',regex=True)\n",
    "df = df.replace(';','',regex=True)\n",
    "df = df.replace('  ','',regex=True)\n",
    "df = df.replace(':','',regex=True)\n",
    "df = df.replace('\"','',regex=True)\n",
    "df = df.replace('\\\\*','',regex=True)\n",
    "df = df.replace('\\*','',regex=True)\n",
    "df = df.replace('_','',regex=True)\n",
    "df = df.replace('\\$','',regex=True)\n",
    "df = df.replace('rt','',regex=True)\n",
    "df = df.replace('//','',regex=True)\n",
    "df = df.replace('/','',regex=True)\n",
    "df = df.replace('#','',regex=True)\n",
    "df = df.replace('\\(','',regex=True)\n",
    "df = df.replace('\\)','',regex=True)\n",
    "df = df.replace('\\'','',regex=True)\n",
    "df = df.replace('\\?','',regex=True)\n",
    "df = df.replace('\\-','',regex=True)\n",
    "df = df.replace('!','',regex=True)\n",
    "\n",
    "df = df.sample(frac=1) #Deixa o df em uma ordem aleatoria\n",
    "\n",
    "L = len(df)\n",
    "Learn = int(L*0.75) #tamanho do df de treinamento\n",
    "Test = int(L*0.25) # tamenho do df de teste\n",
    "\n",
    "dfLearn = df.iloc[0:Learn] #df de treinamento\n",
    "dfLearn = dfLearn.reset_index(drop=True)\n",
    "\n",
    "dfTest = df.iloc[Learn:L] #df de teste\n",
    "dfTest = dfTest.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ham = []\n",
    "Spam =[]\n",
    "NSpam = 0\n",
    "\n",
    "for index, row in dfLearn.iterrows(): #Percorre o df linha por linha\n",
    "    if row['Class'] == 'spam':\n",
    "        linha = row['Email']\n",
    "        Linha = linha.split() #Separa as palavras do conteúdo do email\n",
    "        NSpam +=1 #Adiciona +1 ao numero de emails de Spam\n",
    "        for palavra in Linha:\n",
    "            Hm = []\n",
    "            for letra in palavra:  #Separa as letras das palavras\n",
    "                if letra.isalpha() == True: # Se a letrea é alfabética:\n",
    "                    Hm.append(letra) \n",
    "            hm  = ''.join(Hm) #Junta as letras em palavra\n",
    "            if len(hm)>1: # Filtra palavras com menos de duas Letras\n",
    "                Spam.append(hm)\n",
    "    else:\n",
    "        linha = str(row['Email'])\n",
    "        Linha = linha.split()  #Separa as palavras do conteúdo do email\n",
    "        for palavra in Linha:\n",
    "            Hm = []\n",
    "            for letra in palavra:\n",
    "                if letra.isalpha() == True: # Se a letrea é alfabética:\n",
    "                    Hm.append(letra)\n",
    "            hm  = ''.join(Hm) #Junta as letras em palavra\n",
    "            if len(hm)>1: # Filtra palavras com menos de duas Letras\n",
    "                Ham.append(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'its', 'LUCY', 'Hubby', 'at', 'meetins', 'all', 'day', 'Fri', 'will']\n"
     ]
    }
   ],
   "source": [
    "print(Spam[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de uma mensagem ser SPAM:  0.1255980861244019 \n",
      "Probabilidade de uma mensagem ser HAM:  0.8744019138755981\n"
     ]
    }
   ],
   "source": [
    "P_Spam = NSpam/len(dfLearn) #Probabilidade de uma mensagem ser SPAM \n",
    "P_Ham = 1-P_Spam #Probabilidade de uma mensagem ser HAM\n",
    "print('Probabilidade de uma mensagem ser SPAM: ',P_Spam, \n",
    "      '\\nProbabilidade de uma mensagem ser HAM: ',P_Ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         No de.am seeing in online shop so that i asked.\n",
       "1       Was actually sleeping and still might when u c...\n",
       "5                                       Wat r u doing now\n",
       "6       Am on a train back from nohampton so im afraid...\n",
       "7       I REALLY NEED 2 KISS U I MISS U MY BABY FROM U...\n",
       "8       Great. Have a safe trip. Dont panic surrender ...\n",
       "9       Ya they are well and fine. BBDpooja full pimpl...\n",
       "10                                 Watching ajith film ah\n",
       "11      \\Getting tickets 4 walsall tue 6 th march. My ...\n",
       "12      Honeybee Said Im d Sweetest in d World God Lau...\n",
       "13               Armand says get your ass over to epsilon\n",
       "14      Hey im bored... So im thinking of u... So wat ...\n",
       "15                       K..i deleted my contact that why\n",
       "16      Hmmm ... I thought we said 2 hours slave not 3...\n",
       "17      Babe Im answering you cant you see me  Maybe y...\n",
       "18      Dunno cos i was v late n when i reach they ins...\n",
       "19                        Customer place i will call you.\n",
       "20      Indians r poor but India is not a poor country...\n",
       "21      U so lousy run already come back then half dea...\n",
       "23            Theoretically yeah he could be able to come\n",
       "24      Okay name ur price as long as its legal Wen ca...\n",
       "25                       Went fast asleep dear.take care.\n",
       "26      I am literally in bed and have been up for lik...\n",
       "27            Can not use foreign stamps in this country.\n",
       "28                         Aight call me once youre close\n",
       "29      hi my darlin im on my way to London and we hav...\n",
       "30      Sorry da thangam very very sorry i am held up ...\n",
       "31      I emailed yifeng my pa oredi.. Can Ì get it fr...\n",
       "32      In the end she might still vomit but its okay....\n",
       "33                             Im on da bus going home...\n",
       "                              ...                        \n",
       "1358    Hello. Damn this christmas thing. I think i ha...\n",
       "1359    Rose needs water season needs change poet need...\n",
       "1360    Oh... Lk tt den we take e one tt ends at cine ...\n",
       "1362               Im e person whos doing e sms survey...\n",
       "1363                            how tall are you princess\n",
       "1364                          Ive reached home finally...\n",
       "1365             Ultimately tor motive tui achieve korli.\n",
       "1367                    I dont think he has spatula hands\n",
       "1368    Now whats your house  again  And do you have a...\n",
       "1369                    Wat time do u wan 2 meet me later\n",
       "1370                       &lt&gtin mca. But not conform.\n",
       "1371    Hey a guy I know is breathing down my neck to ...\n",
       "1372    They are just making it easy to pay back. I ha...\n",
       "1373    You have come into my life and brought the sun...\n",
       "1374       staff.science.nus.edu.sg~phyhcmkteachingpc1323\n",
       "1375                                ÌÏ all write or wat..\n",
       "1376                               I fetch yun or u fetch\n",
       "1377    Yes it completely in out of formclark also utt...\n",
       "1379                                 Sorry Ill call later\n",
       "1381    Well I meant as opposed to my drunken night of...\n",
       "1382                                            Yup ok...\n",
       "1383    Hi Princess Thank you for the pics. You are ve...\n",
       "1384    Dont hesitate. You know this is the second tim...\n",
       "1387    Best line said in Love . \\I will wait till the...\n",
       "1388                                              Thank u\n",
       "1389    I cant wait to see you How were the photos wer...\n",
       "1390                           Do you work all this week \n",
       "1391    No dear i do have free messages without any re...\n",
       "1392    Every King Was Once A Crying Baby And Every Gr...\n",
       "1393                      Ok i msg u b4 i leave my house.\n",
       "Name: Email, Length: 1172, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ham =dfTest[dfTest.Class == 'ham']\n",
    "d_spam =dfTest[dfTest.Class == 'spam']\n",
    "d_ham.Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_ham = np.sum(d_ham.Email + \" \").split()\n",
    "vh= pd.Series(lista_ham)\n",
    "vh.value_counts()\n",
    "lista_spam = np.sum(d_spam.Email + \" \").split()\n",
    "vs= pd.Series(lista_spam)\n",
    "vs.value_counts()\n",
    "lista_spam.count('to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsp= len(lista_spam)\n",
    "lha= len(lista_ham)\n",
    "x = \"SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\"\n",
    "def email(x):\n",
    "    spams = []\n",
    "    hams = []\n",
    "    sep=x.split(' ')\n",
    "    for i in range(len(sep)):\n",
    "        spams.append((lista_spam.count(sep[i])/lsp))\n",
    "        hams.append((lista_ham.count(sep[i])/lha))\n",
    "    pps = np.prod(spams)\n",
    "    pph = np.prod(hams)\n",
    "    if pph > pps:\n",
    "        return \"S\"\n",
    "    else:\n",
    "        return \"N\"\n",
    "email(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 5. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
